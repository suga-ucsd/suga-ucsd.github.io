<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>üíª Subhadeep's Projects üíª</title>
    <link rel="stylesheet" href="index.css">
    <style>
        .projects-container {
            max-width: 1200px;
            margin: 0 auto;
        }

        .project-section {
            margin-bottom: 40px;
        }

        .section-header {
            background: linear-gradient(90deg, var(--neon-pink), var(--neon-blue));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            font-family: 'Press Start+2P', cursive;
            font-size: 24px;
            text-align: center;
            margin: 40px 0 30px 0;
            padding: 20px;
            border: 3px solid var(--neon-pink);
            box-shadow: 0 0 20px var(--neon-pink);
        }

        details {
            background: linear-gradient(135deg, #1a1a2e, #16213e);
            border: 3px solid var(--neon-green);
            margin: 25px 0;
            padding: 0;
            transition: all 0.3s;
            box-shadow: 0 0 15px rgba(0, 255, 0, 0.3);
        }

        details:hover {
            border-color: var(--neon-pink);
            box-shadow: 0 0 25px rgba(255, 16, 240, 0.5);
            transform: translateY(-5px);
        }

        details[open] {
            border-color: var(--neon-blue);
            box-shadow: 0 0 30px rgba(0, 240, 255, 0.6);
        }

        summary {
            cursor: pointer;
            list-style: none;
            padding: 20px;
            background: rgba(0, 255, 0, 0.05);
            transition: all 0.3s;
        }

        summary::-webkit-details-marker {
            display: none;
        }

        summary:hover {
            background: rgba(0, 255, 0, 0.1);
        }

        .summary-container {
            display: flex;
            align-items: center;
            gap: 25px;
            flex-wrap: wrap;
        }

        .summary-image {
            width: 180px;
            height: 120px;
            border: 3px solid var(--neon-yellow);
            display: flex;
            align-items: center;
            justify-content: center;
            background: rgba(255, 255, 0, 0.1);
            font-size: 14px;
            font-family: 'Press Start+2P', cursive;
            color: var(--neon-yellow);
            text-shadow: 0 0 10px var(--neon-yellow);
            flex-shrink: 0;
            position: relative;
            overflow: hidden;
        }

        .summary-image::before {
            content: 'üñºÔ∏è';
            font-size: 48px;
            position: absolute;
            animation: float 3s ease-in-out infinite;
        }

        @keyframes float {
            0%, 100% { transform: translateY(0); }
            50% { transform: translateY(-10px); }
        }

        .summary-title {
            flex: 1;
            min-width: 300px;
        }

        .summary-title > span:first-child {
            font-size: 22px;
            font-weight: bold;
            color: var(--neon-blue);
            text-shadow: 0 0 10px var(--neon-blue);
            display: block;
            margin-bottom: 8px;
        }

        .summary-title .lab-name {
            font-weight: normal;
            font-size: 16px;
            color: var(--neon-green);
            text-shadow: 0 0 5px var(--neon-green);
        }

        .expanded-content {
            padding: 30px;
            background: rgba(0, 0, 0, 0.3);
            border-top: 2px solid var(--neon-blue);
            animation: slideDown 0.3s ease-out;
        }

        @keyframes slideDown {
            from {
                opacity: 0;
                transform: translateY(-20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .expanded-image {
            width: 100%;
            max-width: 700px;
            height: 350px;
            border: 3px solid var(--neon-pink);
            margin: 0 auto 25px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            background: rgba(255, 16, 240, 0.1);
            font-size: 18px;
            font-family: 'Press Start+2P', cursive;
            color: var(--neon-pink);
            text-shadow: 0 0 10px var(--neon-pink);
            position: relative;
            overflow: hidden;
        }

        .expanded-image::before {
            content: 'üì∏';
            font-size: 80px;
            position: absolute;
            animation: pulse 2s ease-in-out infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 0.5; }
            50% { transform: scale(1.1); opacity: 1; }
        }

        .expanded-content p {
            font-size: 18px;
            line-height: 1.8;
            color: var(--neon-green);
            margin: 20px 0;
            text-align: left;
            padding: 15px;
            background: rgba(0, 255, 0, 0.05);
            border-left: 4px solid var(--neon-green);
        }

        .project-badge {
            display: inline-block;
            background: var(--neon-pink);
            color: black;
            padding: 5px 10px;
            font-family: 'Press Start+2P', cursive;
            font-size: 10px;
            margin-right: 10px;
            box-shadow: 0 0 10px var(--neon-pink);
            animation: blink 2s infinite;
        }

        .tech-stack {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin-top: 20px;
            padding: 15px;
            background: rgba(0, 240, 255, 0.05);
            border: 2px dashed var(--neon-blue);
        }

        .tech-tag {
            background: var(--widget-bg);
            color: var(--neon-blue);
            border: 2px solid var(--neon-blue);
            padding: 5px 12px;
            font-size: 14px;
            font-family: 'VT323', monospace;
            text-shadow: 0 0 5px var(--neon-blue);
            transition: all 0.3s;
        }

        .tech-tag:hover {
            background: var(--neon-blue);
            color: black;
            box-shadow: 0 0 15px var(--neon-blue);
            transform: scale(1.1);
        }

        @media (max-width: 768px) {
            .summary-container {
                flex-direction: column;
                text-align: center;
            }

            .summary-image {
                width: 100%;
                max-width: 300px;
            }

            .section-header {
                font-size: 16px;
            }

            .expanded-image {
                height: 250px;
            }
        }
    </style>
</head>
<body>
    <div class="stars"></div>
    <div class="container">
        <header class="rainbow-border">
            <marquee behavior="scroll" direction="left" class="marquee-top">
                üöÄ MY PROJECTS üöÄ RESEARCH & ENGINEERING üöÄ AI/ML/ROBOTICS üöÄ LET'S BUILD THE FUTURE üöÄ
            </marquee>
            <h1 class="glitch" data-text="MY PROJECTS">MY PROJECTS</h1>
            <div class="pixel-art">
                <pre>
  ___  ___  ___     _ ___ ___ _____ ___ 
 | _ \| _ \/ _ \  | | __/ __|_   _/ __|
 |  _/|   / (_) |_| | _| (__  | | \__ \
 |_|  |_|_\\___/___/|___\___| |_| |___/
                </pre>
            </div>
            <nav class="nav-buttons">
                <a href="index.html" class="btn">üè† HOME</a>
                <a href="index.html#about" class="btn">üë§ ABOUT</a>
                <a href="index.html#publications" class="btn">üìö PAPERS</a>
                <a href="projects.html" class="btn active">üíª PROJECTS</a>
                <a href="index.html#research-interests" class="btn">üî¨ RESEARCH</a>
                <a href="blog.html" class="btn">üìù BLOG</a>
                <a href="resume.pdf" class="btn">üìÑ RESUME</a>
                <a href="index.html#contact" class="btn">üìß CONTACT</a>
            </nav>
        </header>

        <div class="main-content">
            <aside class="sidebar-left">
                <div class="widget">
                    <h3>üìä PROJECT STATS</h3>
                    <p style="font-size: 14px;">
                        Total Projects: <b class="blink" style="color: var(--neon-pink);">8+</b><br>
                        Research Labs: <b>2</b><br>
                        GPUs Melted: <b>‚àû</b><br>
                        Code Lines: <b>100k+</b><br>
                        Coffee Consumed: <b>9001‚òï</b>
                    </p>
                </div>

                <div class="widget">
                    <h3>üî• TECH STACK</h3>
                    <div class="button-grid">
                        <button class="mini-btn">PyTorch</button>
                        <button class="mini-btn">JAX</button>
                        <button class="mini-btn">Ray</button>
                        <button class="mini-btn">C++</button>
                        <button class="mini-btn">CUDA</button>
                        <button class="mini-btn">Docker</button>
                        <button class="mini-btn">gRPC</button>
                        <button class="mini-btn">FastAPI</button>
                    </div>
                </div>

                <div class="widget">
                    <h3>üèÜ ACHIEVEMENTS</h3>
                    <ul style="list-style: none; padding: 0; font-size: 14px;">
                        <li>‚úì 90%+ GPU scaling</li>
                        <li>‚úì Sub-second latency</li>
                        <li>‚úì 128 parallel envs</li>
                        <li>‚úì 20M training pairs</li>
                        <li>‚úì Production RAG</li>
                    </ul>
                </div>

                <div class="widget">
                    <h3>‚ö° QUICK NAV</h3>
                    <ul class="link-list">
                        <li><a href="#research-lab">Research Labs</a></li>
                        <li><a href="#systems-ml">Systems & ML</a></li>
                        <li><a href="index.html">Back Home</a></li>
                    </ul>
                </div>
            </aside>

            <main>
                <div class="projects-container">
                    <div class="project-section" id="research-lab">
                        <h2 class="section-header">
                            üî¨ RESEARCH & LAB PROJECTS üî¨
                        </h2>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>ü§ñ LLM-Based Agentic RAG for Large Codebases</span>
                                        <span class="lab-name">üìç MURO Lab, UC San Diego</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    This project focused on designing and deploying a production-grade, agentic
                                    Retrieval-Augmented Generation system to help developers explore and reason
                                    over large research codebases. The system was architected as a set of Ray Serve
                                    microservices enabling scalable embedding generation, retrieval, and inference
                                    across both CPUs and GPUs.
                                </p>
                                <p>
                                    The language model was fine-tuned using pipeline parallelism and gradient
                                    checkpointing, while dense retrieval and inference were optimized with custom
                                    multiprocessing queues and CUDA-aware memory management. The final system
                                    achieved sub-second latency under concurrent load and demonstrated strong
                                    reliability for real-world usage by research teams.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">Ray Serve</span>
                                    <span class="tech-tag">PyTorch</span>
                                    <span class="tech-tag">CUDA</span>
                                    <span class="tech-tag">RAG</span>
                                    <span class="tech-tag">LLM</span>
                                    <span class="tech-tag">Microservices</span>
                                </div>
                            </div>
                        </details>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>ü¶æ Scalable Vision-Based Robotic Grasping</span>
                                        <span class="lab-name">üìç Existential Robotics Lab, UC San Diego</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    In this work, I led the development of a highly scalable robotic learning
                                    framework enabling vision-based grasping experiments across 64‚Äì128
                                    parallel simulated environments. The system relied on multi-process PyTorch
                                    pipelines orchestrated with Ray and torch.multiprocessing to efficiently
                                    vectorize CNN rollouts.
                                </p>
                                <p>
                                    GPU offloading via CuPy significantly reduced CPU bottlenecks and accelerated
                                    reinforcement learning training by more than an order of magnitude. The entire
                                    workflow was containerized using Docker to ensure reproducibility, fault
                                    tolerance, and rapid experimentation across multi-GPU systems.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">PyTorch</span>
                                    <span class="tech-tag">Ray</span>
                                    <span class="tech-tag">CuPy</span>
                                    <span class="tech-tag">Docker</span>
                                    <span class="tech-tag">RL</span>
                                    <span class="tech-tag">Computer Vision</span>
                                    <span class="tech-tag">Robotics</span>
                                </div>
                            </div>
                        </details>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>üìê Differentiable SDF-Based Robotic Simulation</span>
                                        <span class="lab-name">üìç Existential Robotics Lab, UC San Diego</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    This project explored the integration of signed distance function models into
                                    robotic simulation pipelines to enable differentiable collision checking and
                                    geometric reasoning. SDF models were implemented using JAX to leverage
                                    auto-vectorized gradient computation for efficient backpropagation.
                                </p>
                                <p>
                                    The resulting system improved simulation fidelity and enabled differentiable
                                    policy optimization for complex robotic manipulation tasks, bridging the gap
                                    between geometric modeling and learning-based control.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">JAX</span>
                                    <span class="tech-tag">SDF</span>
                                    <span class="tech-tag">Simulation</span>
                                    <span class="tech-tag">Robotics</span>
                                    <span class="tech-tag">Differentiable</span>
                                </div>
                            </div>
                        </details>
                    </div>

                    <div class="project-section" id="systems-ml">
                        <h2 class="section-header">
                            ‚öôÔ∏è SYSTEMS, LLMs & DISTRIBUTED ML ‚öôÔ∏è
                        </h2>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>üîß LLM Inference Engine From Scratch</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    I implemented a GPT-style inference engine from first principles in C++ and
                                    Python, focusing on low-latency and high-throughput inference. The engine
                                    supports KV caching, paged attention, and incremental token decoding using
                                    contiguous memory layouts.
                                </p>
                                <p>
                                    Dynamic batching and streaming generation were exposed via FastAPI and gRPC,
                                    while kernel-level profiling with NVIDIA Nsight guided optimizations for cache
                                    residency and stream concurrency. Performance was benchmarked against
                                    vLLM-style baselines to identify system bottlenecks.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">C++</span>
                                    <span class="tech-tag">Python</span>
                                    <span class="tech-tag">FastAPI</span>
                                    <span class="tech-tag">gRPC</span>
                                    <span class="tech-tag">CUDA</span>
                                    <span class="tech-tag">KV Cache</span>
                                    <span class="tech-tag">Nsight</span>
                                </div>
                            </div>
                        </details>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>üéÆ Reinforcement Learning for Robotic Control at Scale</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    This project explored large-scale reinforcement learning for robotic
                                    manipulation by training SAC and Transformer-based policies in MuJoCo
                                    simulation. Thousands of environments were executed in parallel using JAX
                                    vmap and pmap, enabling high-throughput policy evaluation and data collection.
                                </p>
                                <p>
                                    Differentiable signed distance function models were integrated into the
                                    simulation loop to provide real-time geometric reasoning and collision
                                    awareness during training. This combination of large-scale parallelism and
                                    differentiable geometry significantly improved learning stability and sample
                                    efficiency for complex robotic control tasks.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">JAX</span>
                                    <span class="tech-tag">MuJoCo</span>
                                    <span class="tech-tag">SAC</span>
                                    <span class="tech-tag">Transformers</span>
                                    <span class="tech-tag">RL</span>
                                    <span class="tech-tag">Robotics</span>
                                </div>
                            </div>
                        </details>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>üñºÔ∏è Large-Scale Vision‚ÄìLanguage Model Training</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    In this project, I designed and trained a CLIP-style vision‚Äìlanguage model on
                                    approximately 20 million image‚Äìtext pairs using PyTorch Distributed Data
                                    Parallel with NCCL collectives. A Ray-based data pipeline handled large-scale
                                    sharded loading and on-the-fly augmentation, significantly reducing GPU idle
                                    time during training.
                                </p>
                                <p>
                                    Training efficiency was further improved through mixed-precision computation,
                                    fused CUDA kernels, and careful tuning of inter-GPU communication. These
                                    optimizations resulted in over 90% scaling efficiency across multiple GPUs,
                                    demonstrating strong performance and stability for large-scale multimodal
                                    pretraining workloads.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">PyTorch DDP</span>
                                    <span class="tech-tag">NCCL</span>
                                    <span class="tech-tag">Ray</span>
                                    <span class="tech-tag">CLIP</span>
                                    <span class="tech-tag">Vision-Language</span>
                                    <span class="tech-tag">20M pairs</span>
                                </div>
                            </div>
                        </details>

                        <details>
                            <summary>
                                <div class="summary-container">
                                    <div class="summary-image"></div>
                                    <div class="summary-title">
                                        <span>üåê Distributed LLM Inference Pipeline</span>
                                        <span class="lab-name">Tensor + Pipeline Parallelism</span>
                                    </div>
                                </div>
                            </summary>
                            <div class="expanded-content">
                                <div class="expanded-image"></div>
                                <p>
                                    This project focused on building a scalable, multi-GPU inference pipeline for
                                    large language models by combining tensor parallelism with pipeline
                                    parallelism. The system was designed to efficiently shard both model weights
                                    and activations across GPUs, enabling inference on models that exceed the
                                    memory capacity of a single device.
                                </p>
                                <p>
                                    A gRPC-based activation sharding protocol was implemented with explicit
                                    backpressure control to stabilize throughput under bursty request patterns.
                                    End-to-end observability was achieved using Grafana and Prometheus dashboards
                                    tracking GPU utilization, per-stage latency, interconnect bandwidth, and queue
                                    depths, enabling systematic performance tuning and reliability analysis.
                                </p>
                                <div class="tech-stack">
                                    <span class="tech-tag">Tensor Parallel</span>
                                    <span class="tech-tag">Pipeline Parallel</span>
                                    <span class="tech-tag">gRPC</span>
                                    <span class="tech-tag">Grafana</span>
                                    <span class="tech-tag">Prometheus</span>
                                    <span class="tech-tag">Multi-GPU</span>
                                </div>
                            </div>
                        </details>
                    </div>
                </div>
            </main>

            <aside class="sidebar-right">
                <div class="widget">
                    <h3>üí° PROJECT TYPES</h3>
                    <ul class="link-list">
                        <li><a href="#research-lab">Research Labs</a></li>
                        <li><a href="#systems-ml">Systems & ML</a></li>
                    </ul>
                </div>

                <div class="widget">
                    <h3>üî• HIGHLIGHTS</h3>
                    <div style="font-size: 14px;">
                        <p class="blink" style="color: var(--neon-pink);">‚ö° 128 Parallel Envs</p>
                        <p class="blink" style="color: var(--neon-blue);">‚ö° Sub-second Latency</p>
                        <p class="blink" style="color: var(--neon-green);">‚ö° 20M Training Pairs</p>
                        <p class="blink" style="color: var(--neon-yellow);">‚ö° 90%+ GPU Scaling</p>
                    </div>
                </div>

                <div class="widget">
                    <h3>üéØ EXPERTISE</h3>
                    <p style="font-size: 14px; line-height: 1.8;">
                        ‚úì Distributed Training<br>
                        ‚úì LLM Inference<br>
                        ‚úì Robotics & RL<br>
                        ‚úì Systems Engineering<br>
                        ‚úì GPU Optimization<br>
                        ‚úì Production ML
                    </p>
                </div>

                <div class="widget">
                    <h3>üìä BY THE NUMBERS</h3>
                    <div style="font-size: 32px; text-align: center; line-height: 1.5;">
                        <span style="color: var(--neon-pink);">8+</span><br>
                        <span style="font-size: 12px; color: var(--neon-green);">PROJECTS</span><br><br>
                        <span style="color: var(--neon-blue);">100k+</span><br>
                        <span style="font-size: 12px; color: var(--neon-green);">LINES OF CODE</span>
                    </div>
                </div>

                <div class="widget">
                    <h3>üöÄ STATUS</h3>
                    <p style="font-size: 14px;">
                        <span class="blink" style="color: var(--neon-green);">‚óè ACTIVE</span><br>
                        Building the future<br>
                        One GPU at a time üî•
                    </p>
                </div>
            </aside>
        </div>

        <footer class="rainbow-border">
            <marquee behavior="scroll" direction="right" class="marquee-bottom">
                üíª PROJECTS SHOWCASE üíª AI/ML/ROBOTICS üíª DISTRIBUTED SYSTEMS üíª RESEARCH & ENGINEERING üíª
            </marquee>
            <p>&copy; 2026 Subhadeep Chatterjee. All rights reserved.</p>
            <p style="font-size: 14px;">Last updated: <span id="date"></span></p>
        </footer>
    </div>

    <script>
        document.getElementById('date').textContent = new Date().toLocaleDateString();

        // Auto-scroll to opened details
        document.querySelectorAll('details').forEach(detail => {
            detail.addEventListener('toggle', function() {
                if (this.open) {
                    setTimeout(() => {
                        this.scrollIntoView({ behavior: 'smooth', block: 'start' });
                    }, 300);
                }
            });
        });
    </script>
</body>
</html>
